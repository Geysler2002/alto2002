---
title: "Proyecto"
author: "Geysler Mariñas Alvarado"
format:
  html:
    toc: true
    toc-location: left
    number-sections: true
    embed-resources: true
    smooth-scroll: true
    anchor-sections: true
    output-file: index
---
# Introducción
En el entorno actual, las organizaciones dependen cada vez más de los datos para tomar decisiones estratégicas y mejorar sus operaciones. Este proyecto de análisis de datos se centra en aprovechar información estructurada y no estructurada para identificar patrones, tendencias y conocimientos clave que puedan guiar las decisiones informadas. A través del uso de técnicas avanzadas de procesamiento, visualización y modelado de datos, se busca transformar grandes volúmenes de información en conocimientos prácticos que agreguen valor.

El objetivo principal de este proyecto es aplicar métodos de análisis de datos para explorar y responder preguntas específicas, utilizando diversas herramientas y tecnologías que nos permitan obtener una visión clara y profunda de los datos disponibles. Además, se generarán visualizaciones que facilitarán la comprensión de los resultados y se propondrán recomendaciones basadas en los resultados obtenidos.

En este documento se detallarán los objetivos específicos del análisis, las metodologías empleadas, así como los resultados y conclusiones obtenidas. De esta forma, se espera que este proyecto sea una herramienta útil para la toma de decisiones basada en datos y contribuya a la optimización y mejora continua de los procesos organizacionales.

![Innovación analitica](https://lisainsurtech.com/wp-content/uploads/2022/01/exploratory-data-analysis-using-python-blog-hero.jpeg)

# Para realizar el proyecto debo

1.  Tener mi proyecto
2.  Conectar mi proyecto a GithUb
3.  Tener un archivo en formato html llamado index.html
4.  Hacer push al repositorio
5.  Activar Github pages


# Modelos lineales


Un modelo lineal es un tipo de modelo estadístico y matemático que asume una relación lineal entre una variable dependiente (respuesta) y una o más variables independientes (predictores o explicativas). La característica clave de los modelos lineales es que la relación entre la variable dependiente y cada predictor es una combinación lineal, lo que significa que la ecuación del modelo tiene la forma:
![modelo lineal](http://3.bp.blogspot.com/-Vz2adH3zaeI/VTPq4T2rmDI/AAAAAAAABr4/K-ssPFWG8Tc/s1600/Regresion_ecuacion_2.jpg)
Los modelos lineales son ampliamente utilizados porque son sencillos de interpretar y calcular, y proporcionan una primera aproximación útil para entender la relación entre las variables en un conjunto de datos. Además, permiten estimar los efectos de los predictores sobre la variable de interés, haciendo posibles inferencias y predicciones.

## Insertar datos

Datos

```{r}
source('https://inkaverse.com/setup.r')

url <- "https://docs.google.com/spreadsheets/d/15r7ZwcZZHbEgltlF6gSFvCTFA-CFzVBWwg3mFlRyKPs/edit?gid=172957346#gid=172957346"

gs <- url %>% 
  as_sheets_id()

fb <- gs %>%
  range_read("fb")

str(fb)
```

# Modelo lineal para lfa

Es también conocido como modelo de factores latentes, es un enfoque utilizado en análisis de datos, especialmente en el campo de aprendizaje automático y sistemas de recomendación, para identificar factores ocultos o "latentes" que explican patrones en los datos.

Datos

```{r}
modelo <- aov(formula = lfa ~ bloque + riego + geno + riego*geno
              , data =fb)

anova(modelo)

plot(modelo)
```

## Boxplot

Un boxplot, también conocido como diagrama de caja y bigotes, es una representación gráfica que muestra la distribución de un conjunto de datos a través de cinco valores clave:

Mínimo: El valor más bajo, excluyendo los valores atípicos (outliers).
Primer cuartil (Q1): El 25% de los datos están por debajo de este valor.
Mediana (Q2): El valor central de los datos, es decir, el 50% de los datos están por debajo de este valor.
Tercer cuartil (Q3): El 75% de los datos están por debajo de este valor.
Máximo: El valor más alto, excluyendo los valores atípicos.

Datos
```{r}
ggplot(fb, aes(x = geno, y = lfa, colour = riego)) + 
         geom_boxplot(outlier.colour = "green", outlier.shape = 16, outlier.size = 2) + 
         labs(title = "Boxplot con interacción de niveles de riego y genotipo",
              x = "Interacción riego y genotipo",
              y = "Área foliar (cm^2)")
         theme_minimal() + 
         theme(axis.text.x = element_text(angle = 45,hjust = 1))
```



# Modelo lineal para hi

Un modelo Líneal HI (Híbrido Inteligente Lineal) en el contexto de modelos de machine learning y análisis de datos es un enfoque que mezcla técnicas lineales con herramientas de inteligencia artificial y aprendizaje automático, para ofrecer soluciones más precisas y adaptativas en aplicaciones específicas

Datos

```{r}
modelo <- aov(formula = hi ~ bloque + riego + geno + riego*geno
              , data =fb)

anova(modelo)
plot(modelo)
```




## Boxplot

Datos
```{r}
ggplot(fb, aes(x = geno, y = hi, colour = riego)) + 
         geom_boxplot(outlier.colour = "blue", outlier.shape = 16, outlier.size = 2) + 
         labs(title = "Boxplot con interacción de niveles de riego y genotipo",
              x = "Interacción riego y genotipo",
              y = "Área foliar (cm^2)")
 theme_minimal() + 
         theme(axis.text.x = element_text(angle = 45,hjust = 1))
```


# Modelo lineal mixto 

Un modelo lineal mixto es un tipo de modelo estadístico que combina efectos fijos y efectos aleatorios para analizar datos en los que existen dependencias o estructuras de agrupamiento. Este modelo es especialmente útil en situaciones donde los datos no son independientes entre sí, sino que están organizados en grupos, como en estudios de datos longitudinales o experimentos con diseños en bloques.

Datos 
```{r}
library(lme4)

model <- lme4::lmer(formula = lfa ~ riego + geno + riego * geno + (1 | bloque), data = fb)

anova(model)
plot(model)
ol <- boxplot(lfa ~ riego * geno, fb)
ol
library(inti)
model <- remove_outliers(data = fb
                         ,formula = lfa ~ riego + geno + riego * geno+ (1 | bloque)
                         , plot_diag = T
                         ) 
model


```


# Agricolae: comparacion de medias 

La prueba de comparación de medias llamada Agricolae se refiere a un conjunto de métodos y funciones de la biblioteca "Agricolae" del software estadístico R. Esta biblioteca es ampliamente utilizada en experimentos agrícolas y estudios científicos para realizar análisis de comparación de medias, pruebas de hipótesis y análisis de varianza, entre otros.

Agricolae ofrece diversas pruebas para comparar medias, como:

Prueba de Tukey (HSD - Honestly Significant Difference): Compara todas las medias posibles en un diseño de análisis de varianza (ANOVA) y determina cuáles medias difieren significativamente entre sí.

Prueba de Duncan: Similar a Tukey, pero generalmente más liberal, es decir, detecta más diferencias significativas.

Prueba de Bonferroni: Ajusta el nivel de significación para evitar el error tipo I cuando se realizan múltiples comparaciones.

Prueba de Scheffé: Útil cuando se desea probar todas las posibles comparaciones lineales de medias, especialmente en estudios de comparación múltiples.

Datos 
```{r}
modelo <- lm(formula = lfa ~ bloque + riego + geno + riego * geno, data = fb)

anova(modelo)
library(agricolae)

tukey_result <- HSD.test(modelo, c("geno", "riego"), group = TRUE)

print(tukey_result)
plot(tukey_result)
```


## Tabla de Tukey
 
Datos
```{r}
tukey_result
grupos <- tukey_result$groups %>% 
  rownames_to_column("tratamientos") %>% 
  separate(tratamientos, into = c("geno", "riego"), sep = ":")
str(grupos)
library(agricolae)
library(ggplot2)
library(dplyr)
library(tidyr)
modelo <- lm(formula = lfa ~ bloque + riego + geno + riego * geno, data = fb)
tukey_result <- HSD.test(modelo, c("geno", "riego"), group = TRUE)
# Crear un dataframe con los grupos y separar los tratamientos
grupos <- tukey_result$groups %>% 
  rownames_to_column("tratamientos") %>% 
  separate(tratamientos, into = c("geno", "riego"), sep = ":")
ggplot(grupos, aes(x = geno, y = lfa, fill = riego)) +  # Asegúrate de que "LFA" sea el nombre correcto
  geom_bar(stat = "identity", position = position_dodge(), color = "black") +
  labs(title = "Comparación de Medias - Prueba de Tukey", 
       x = "Genotipos", 
       y = "FTL") +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  scale_fill_discrete(name = "Riego")
```

### Grafico de comparación de media: Tunkey

Datos

```{r}
ggplot(grupos, aes(x = geno, y = lfa, fill = riego)) +  # Asegúrate de que "lfa" sea el nombre correcto
  geom_bar(stat = "identity", position = position_dodge(), color = "black") +
  labs(title = "Comparación de Medias - Prueba de Tukey", 
       x = "Genotipos", 
       y = "FTL") +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  scale_fill_discrete(name = "Riego") +
  geom_text(aes(label = groups, y = lfa + 0.05),  # Usar 'groups' en lugar de 'M'
            position = position_dodge(0.9), vjust = 0)  # Ajustar el espaciado de las letras
```

# Emmeans: Comparación de medias 

Emmeans es una abreviatura para "Estimated Marginal Means" o "Medias Marginales Estimadas". En el contexto del análisis estadístico, emmeans se refiere a una técnica utilizada para realizar comparaciones de medias ajustadas en modelos estadísticos, especialmente cuando se emplean modelos lineales generalizados (como ANOVA, regresión lineal y otros modelos de efectos mixtos). En particular, el paquete emmeans en R facilita este tipo de análisis.

¿Para qué se utiliza emmeans?
Cuando se desea comparar las medias de distintos grupos o niveles de un factor en un modelo, es útil ajustar las medias para tener en cuenta otros factores en el modelo. Esto permite obtener una comparación más precisa y menos sesgada, ya que emmeans estima la media de cada grupo controlando o ajustando por los efectos de otras variables.

Datos

```{r}
model <- lme4::lmer(formula = hi ~ riego + geno + riego * geno + (1 | bloque), data = fb)

anova(model)
library(emmeans)
library(multicmp)
library(multcompView)

cm1 <- emmeans(model, ~ geno | riego) %>%
  cld(Letters=letters, reversed = T)
cm1
cm2 <- emmeans(model, ~ riego | geno) %>%
  cld(Letters=letters, reversed = T)
cm2
cm3 <- emmeans(model, ~ riego * geno) %>%
  cld(Letters=letters, reversed = T)
cm3

```

## Grafícas 

```{r}
cm1_df <- as.data.frame(cm1)
ggplot(cm1_df, aes(x = geno, y = emmean, fill = riego)) +  # Cambia "emmean" por la columna de las medias estimadas
  geom_bar(stat = "identity", position = position_dodge(), color = "black") +
  labs(title = "Comparación de Medias - Medias Estimadas", 
       x = "Genotipos", 
       y = "hi") +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  scale_fill_discrete(name = "Riego")
dtcm <- as.data.frame(cm2) %>% 
  rename(sig = ".group")

ggplot(dtcm, aes(x = geno, y = emmean, fill = riego)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  geom_text(aes(label = sig, y = emmean*1*1),
            position = position_dodge(width = 0.9),
            vjust = 0) +
  labs(x = "Genotipo", y = "HI", fill = "Riego") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Gráfico de barras: LFA por genotipo y riego")
```

# Analisís multivariado

El análisis multivariado es un conjunto de técnicas estadísticas que permite analizar y entender datos que involucran múltiples variables al mismo tiempo. A diferencia del análisis univariado (que examina una variable) o bivariado (dos variables), el análisis multivariado permite estudiar las relaciones e interacciones entre tres o más variables simultáneamente. Esto es particularmente útil en estudios donde los fenómenos son complejos y dependen de múltiples factores interrelacionados.

¿Para qué se usa?
El análisis multivariado es ampliamente utilizado en diversas áreas como las ciencias sociales, la biología, la economía, la psicología, el marketing, entre otras, para:

Identificar patrones y relaciones complejas entre varias variables.
Reducir dimensionalidad de los datos, es decir, reducir el número de variables conservando la mayor cantidad de información posible (por ejemplo, mediante el análisis de componentes principales).
Clasificar y segmentar datos, ayudando a agrupar observaciones similares.
Predecir valores de variables dependientes con base en múltiples variables independientes.

Datos

```{r}
str(fb)

```

# Correlación

La correlación es una medida estadística que indica la relación y el grado de asociación entre dos variables. En términos simples, muestra si existe una conexión entre dos conjuntos de datos y qué tan fuerte es esa conexión. Se expresa con un valor numérico, llamado coeficiente de correlación, que oscila entre -1 y 1:

1 indica una correlación positiva perfecta: cuando una variable aumenta, la otra también lo hace de manera proporcional.
-1 indica una correlación negativa perfecta: cuando una variable aumenta, la otra disminuye de manera proporcional.
0 indica que no hay correlación: no existe ninguna relación entre las variables.

Datos 

```{r}
library(tidyverse)
library(psych)

fb %>%
  select_if(is.numeric) %>% 
  dplyr::select(!c("block")) %>%
                   pairs.panels(x = .
             , hist.col="red"
             , pch = 21
             , stars = TRUE
             , scale = FALSE
             , lm = TRUE
             )
```

# PCA: Analisís de componentes principales 

El Análisis de Componentes Principales es una técnica de reducción de dimensionalidad usada en el análisis de datos y en la ciencia de datos. Su principal propósito es simplificar conjuntos de datos grandes y complejos sin perder mucha información relevante. PCA transforma un conjunto de variables posiblemente correlacionadas en un conjunto de variables nuevas, llamadas componentes principales, que son no correlacionadas entre sí y capturan la mayor parte de la variabilidad del conjunto de datos original.

¿Cómo funciona PCA?
Estandarización de datos: Se asegura que los datos estén en una escala comparable, ya que PCA es sensible a las diferencias de escala.

Cálculo de la matriz de covarianza: Se calcula la matriz de covarianza de los datos estandarizados para ver cómo varían las variables entre sí.

Cálculo de valores propios y vectores propios: Se obtienen los valores propios y vectores propios de la matriz de covarianza para identificar las direcciones de máxima varianza en los datos.

Selección de componentes principales: Los vectores propios, ordenados por la magnitud de sus valores propios, representan los componentes principales. Los primeros componentes explican la mayor cantidad de varianza en los datos.

Proyección de los datos: Los datos originales se proyectan sobre los componentes seleccionados para obtener una representación reducida del conjunto de datos.

Datos

```{r}
library(FactoMineR)
mv <- fb %>%
  group_by(riego, geno) %>%
  summarise(across(where(is.numeric), ~ mean(., na.rm =TRUE))) %>%
  PCA(scale.unit = T, quali.sup = c(1:4), graph = F)

p1 <- plot(mv
     , choix="ind"
     , habillage=1)

p2 <- plot(mv
     , choix="var")
list(p1, p2) %>%
  plot_grid(plotlist = .,nrow = 1)
```

# Agradecimiento 

![I appreciate your visit](https://www.lifeder.com/wp-content/uploads/2018/03/estoy-muy-agradecido-min-1068x758.jpg)


